defaults:
  - trainer: default
model: togethercomputer/RedPajama-INCITE-7B-Base
log_dir: "/scratch/c.scmse/Funtuner-logs"
log_wandb: true
run_name: ""
wandb_entity: "shahules786"
max_length: 2048
per_digit_tokens: False
special_tokens:
  eos_token: "</s>"
  sep_token: "<sep>"
  pad_token: "<pad>"
datasets:

  - Dahoas/cot_gsm8k:
        split: ["train","val"]

validation_size: 0.1
deepspeed: true
deepspeed_config: "./funtuner/config/zero2.json"
LoRa: true 
LoraConfig:
  r: 8
  target_modules: ["query_key_value"]
  lora_alpha: 16
  bias: none
  lora_dropout: 0.05
  task_type: CAUSAL_LM
  inference_mode: false
  modules_to_save: ["wte", "lm_head"]
eight_bit_training: false
template: orca-style